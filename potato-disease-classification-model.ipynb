{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import all the Dependencies","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import models , layers \nimport matplotlib.pyplot as plt \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:31:25.922215Z","iopub.execute_input":"2023-09-14T13:31:25.923002Z","iopub.status.idle":"2023-09-14T13:31:25.929306Z","shell.execute_reply.started":"2023-09-14T13:31:25.922962Z","shell.execute_reply":"2023-09-14T13:31:25.928359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set all the Constents","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32 \nIMAGE_SIZE = 256 \nCHANNELS = 3\nEPOCHS = 50 ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:36:22.161351Z","iopub.execute_input":"2023-09-14T13:36:22.161765Z","iopub.status.idle":"2023-09-14T13:36:22.169364Z","shell.execute_reply.started":"2023-09-14T13:36:22.161735Z","shell.execute_reply":"2023-09-14T13:36:22.166991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data into tensorflow dataset","metadata":{}},{"cell_type":"code","source":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n  \"/kaggle/input/plantvillagepotato/PlantVillage\",\n   seed=123 ,\n    shuffle=True,\n   image_size = (IMAGE_SIZE , IMAGE_SIZE ),\n   batch_size = BATCH_SIZE \n)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:36:25.236877Z","iopub.execute_input":"2023-09-14T13:36:25.237796Z","iopub.status.idle":"2023-09-14T13:36:26.181573Z","shell.execute_reply.started":"2023-09-14T13:36:25.237755Z","shell.execute_reply":"2023-09-14T13:36:26.180372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = dataset.class_names\nclass_names","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:36:59.369566Z","iopub.execute_input":"2023-09-14T13:36:59.369957Z","iopub.status.idle":"2023-09-14T13:36:59.379943Z","shell.execute_reply.started":"2023-09-14T13:36:59.369926Z","shell.execute_reply":"2023-09-14T13:36:59.378289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_batch , label_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(label_batch.numpy())","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:38:35.144358Z","iopub.execute_input":"2023-09-14T13:38:35.144835Z","iopub.status.idle":"2023-09-14T13:38:35.685614Z","shell.execute_reply.started":"2023-09-14T13:38:35.144798Z","shell.execute_reply":"2023-09-14T13:38:35.684540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize some of the images for our datasets","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10 ,10))\nfor image_batch, label_batch in dataset.take(1):\n    for i in range(12):\n        ax = plt.subplot(3 ,4 , i + 1) \n        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")\n        plt.title(class_names[label_batch[i]])\n      ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:48:59.522597Z","iopub.execute_input":"2023-09-14T13:48:59.522990Z","iopub.status.idle":"2023-09-14T13:49:02.124044Z","shell.execute_reply.started":"2023-09-14T13:48:59.522960Z","shell.execute_reply":"2023-09-14T13:49:02.122685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function to Split Dataset\nDataset should be bifurcated into 3 subsets, namely:\n\n1. Training: Dataset to be used while training\n2. Validation: Dataset to be tested against while training\n3. Test: Dataset to be tested against after we trained a model","metadata":{}},{"cell_type":"code","source":"def get_dataset_partitions_tf(ds , train_split=0.8 , val_split=0.1 , test_split=0.1 , shuffle=True , shuffle_size=10000):\n    assert(train_split + val_split + test_split ) == 1\n    \n    ds_size = len(ds)\n    \n    if shuffle:\n        ds = ds.shuffle(shuffle_size , seed=123)\n    \n    train_size = int( train_split * ds_size)\n    val_size = int(val_split * ds_size)\n    \n    train_ds = ds.take(train_size)\n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n    return train_ds , val_ds , test_ds ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:04:12.283115Z","iopub.execute_input":"2023-09-14T14:04:12.283751Z","iopub.status.idle":"2023-09-14T14:04:12.291640Z","shell.execute_reply.started":"2023-09-14T14:04:12.283710Z","shell.execute_reply":"2023-09-14T14:04:12.290411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, val_ds , test_ds = get_dataset_partitions_tf(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:05:20.765355Z","iopub.execute_input":"2023-09-14T14:05:20.765793Z","iopub.status.idle":"2023-09-14T14:05:20.781257Z","shell.execute_reply.started":"2023-09-14T14:05:20.765759Z","shell.execute_reply":"2023-09-14T14:05:20.779955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Len Train_ds: {} , Len Val_ds: {} , Len Test_ds: {}\".format(len(train_ds), len(val_ds), len(test_ds)))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:08:40.810206Z","iopub.execute_input":"2023-09-14T14:08:40.810671Z","iopub.status.idle":"2023-09-14T14:08:40.817504Z","shell.execute_reply.started":"2023-09-14T14:08:40.810638Z","shell.execute_reply":"2023-09-14T14:08:40.816489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cache,Shuffle and Prefetch the Dataset","metadata":{}},{"cell_type":"code","source":"train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\nval_ds =  val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\ntest_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:17:21.692784Z","iopub.execute_input":"2023-09-14T14:17:21.693680Z","iopub.status.idle":"2023-09-14T14:17:21.706125Z","shell.execute_reply.started":"2023-09-14T14:17:21.693637Z","shell.execute_reply":"2023-09-14T14:17:21.704722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model\n**Creating a Layer for Resizing and Normalization**\n\nBefore we feed our images to network, we should be resizing it to the desired size. Moreover, to improve model performance, we should normalize the image pixel value (keeping them in range 0 and 1 by dividing by 256). This should happen while training as well as inference. Hence we can add that as a layer in our Sequential Model.\n\nYou might be thinking why do we need to resize (256,256) image to again (256,256). You are right we don't need to but this will be useful when we are done with the training and start using the model for predictions. At that time somone can supply an image that is not (256,256) and this layer will resize it","metadata":{}},{"cell_type":"code","source":"resizing_rescaling = tf.keras.Sequential([\n    layers.experimental.preprocessing.Resizing(IMAGE_SIZE , IMAGE_SIZE),\n    layers.experimental.preprocessing.Rescaling(1/255.)\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:22:45.565693Z","iopub.execute_input":"2023-09-14T14:22:45.566167Z","iopub.status.idle":"2023-09-14T14:22:45.593621Z","shell.execute_reply.started":"2023-09-14T14:22:45.566133Z","shell.execute_reply":"2023-09-14T14:22:45.592072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmention\n\nData Augmentation is needed when we have less data, this boosts the accuracy of our model by augmenting the data.","metadata":{}},{"cell_type":"code","source":"data_augmention = tf.keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(0.2)\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:28:36.967961Z","iopub.execute_input":"2023-09-14T14:28:36.968502Z","iopub.status.idle":"2023-09-14T14:28:36.985167Z","shell.execute_reply.started":"2023-09-14T14:28:36.968466Z","shell.execute_reply":"2023-09-14T14:28:36.983387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying Data Augmentaion for training data","metadata":{}},{"cell_type":"code","source":"train_ds = train_ds.map(\nlambda x , y : (data_augmention( x , training=True ) , y)\n).prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:38:04.028224Z","iopub.execute_input":"2023-09-14T14:38:04.028964Z","iopub.status.idle":"2023-09-14T14:38:04.219222Z","shell.execute_reply.started":"2023-09-14T14:38:04.028919Z","shell.execute_reply":"2023-09-14T14:38:04.217683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture\n\nWe use a CNN coupled with a Softmax activation in the output layer. We also add the initial layers for resizing, normalization and Data Augmentation.\n\n**We are going to use convolutional neural network (CNN) here. CNN is popular for image classification tasks. Watch below video to understand fundamentals of CNN**","metadata":{}},{"cell_type":"code","source":"input_shape = (BATCH_SIZE , IMAGE_SIZE , IMAGE_SIZE , CHANNELS)\nn_classes = 3\n\nmodel = tf.keras.Sequential([\n    resizing_rescaling , \n    layers.Conv2D(32 , kernel_size=(3,3) , activation='relu' , input_shape=input_shape),\n    layers.MaxPooling2D((2,2)),\n    layers.Conv2D(64 , kernel_size=(3,3) , activation='relu' ),\n    layers.MaxPooling2D((2,2)) ,\n    layers.Conv2D(64 , kernel_size=(3,3) , activation='relu' ),\n    layers.MaxPooling2D((2,2)) ,\n    layers.Conv2D(64 , kernel_size=(3,3) , activation='relu' ),\n    layers.MaxPooling2D((2,2)) ,\n    layers.Conv2D(64 , kernel_size=(3,3) , activation='relu' ),\n    layers.MaxPooling2D((2,2)) ,\n    layers.Conv2D(64 , kernel_size=(3,3) , activation='relu' ),\n    layers.MaxPooling2D((2,2)) ,\n    layers.Flatten(),\n    layers.Dense(64 , activation='relu'),\n    layers.Dense(n_classes , activation='softmax'),\n])\nmodel.build(input_shape=input_shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:56:08.088071Z","iopub.execute_input":"2023-09-14T14:56:08.089269Z","iopub.status.idle":"2023-09-14T14:56:08.289812Z","shell.execute_reply.started":"2023-09-14T14:56:08.089233Z","shell.execute_reply":"2023-09-14T14:56:08.288646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:56:28.522047Z","iopub.execute_input":"2023-09-14T14:56:28.522452Z","iopub.status.idle":"2023-09-14T14:56:28.583914Z","shell.execute_reply.started":"2023-09-14T14:56:28.522422Z","shell.execute_reply":"2023-09-14T14:56:28.582591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compiling the Model\n\nWe use adam Optimizer, SparseCategoricalCrossentropy for losses, accuracy as a metric","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer=\"adam\" ,\n    loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics=['accuracy']\n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:59:07.065540Z","iopub.execute_input":"2023-09-14T14:59:07.066490Z","iopub.status.idle":"2023-09-14T14:59:07.092567Z","shell.execute_reply.started":"2023-09-14T14:59:07.066445Z","shell.execute_reply":"2023-09-14T14:59:07.091313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_ds , batch_size = BATCH_SIZE , validation_data=val_ds , verbose=1 , epochs= EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:01:09.388168Z","iopub.execute_input":"2023-09-14T15:01:09.389083Z","iopub.status.idle":"2023-09-14T15:01:41.622910Z","shell.execute_reply.started":"2023-09-14T15:01:09.389038Z","shell.execute_reply":"2023-09-14T15:01:41.620635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}